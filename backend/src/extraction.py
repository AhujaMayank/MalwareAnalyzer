import pickle
import pandas as pd
from datetime import datetime
from pytz import timezone    

import androguard
import androguard.misc
import androguard as ag

from sklearn.preprocessing import StandardScaler, MinMaxScaler

from backend.src import reduction
from backend.src import constants


# Class to extract feature from the android application for testing and training purposes.
class FeatureExtraction:
  # Set the class data
  # keep the path of pickle file in mind

   
  official_intents = []
  official_permissions = []
  def __init__(self):
    self.reduction_technique = reduction.ReductionTechniques()
    with open(constants.official_permission_intents_file_path,'rb') as f:
      official_permissions_and_intents = pickle.load(f)
      self.official_intents = official_permissions_and_intents['official_intents_list']
      self.official_permissions = official_permissions_and_intents['official_permissions_list']
      f.close()
  
  # Scale the extracted lsi/lda topics 
  def scale_obtained_topics(self, feature_vector, ScalerType=StandardScaler):
    scaler = ScalerType()
    return scaler.fit_transform(feature_vector)

  # One hot encodes permissions and intents based on the official permission and intents list.
  # permission_or_intenst = extracted permission or intents in a dictionary format
  # is_permission = to determine whether permissions_or_intents is for permissions or intents
  # return a one hot encoded list.
  def one_hot_encode(self, permissions_or_intents, is_permission):
    one_hot_encoding = []
    if is_permission:
      for permission in self.official_permissions:
        if permission in permissions_or_intents:
          one_hot_encoding.append(1)
        else:
          one_hot_encoding.append(0) 
    else:
      for intent in self.official_intents:
        if intent in permissions_or_intents:
          one_hot_encoding.append(1)
        else:
          one_hot_encoding.append(0)
    return one_hot_encoding

  # Adds the permissions and intents to the final feature vector.
  def add_permission_and_intents_to_feature_vector(self, features, feature_vector):
    for permission in features['permissions']:
      feature_vector.append(permission)
    
    for intent in features['intents']:
      feature_vector.append(intent)
    
    return feature_vector

  # Extract fearures from single application
  def extract_feature_from_application(self, location):
    a, d, dx = ag.misc.AnalyzeAPK(location,raw=True)

    #Extract permissions used by application
    permissions_dictionary = {}
    for permission in a.get_permissions():
      permissions_dictionary[permission] = True 
    # One hot encode permissions
    permissions = self.one_hot_encode(permissions_dictionary, is_permission=True)
      
    # Extract intents by traversing manifest file
    intents_dictionary = {}
    manifestLineByLine = a.get_android_manifest_xml()
    for app in manifestLineByLine.findall('application'):
      for typeOfIntent in ['activity','receiver','service']:
        for act in app.findall(typeOfIntent):
          for inf in act.findall('intent-filter'):
            for action in inf.findall('action'):
              action_name = action.attrib.get('{http://schemas.android.com/apk/res/android}name')
              intents_dictionary[action_name] = True
    # One hot encode intents
    intents  = self.one_hot_encode(intents_dictionary, is_permission=False)  
      
    #Extract opcodes and api calls.
    opcodes = {}
    d_api = {}
    for method in dx.get_methods():
      # check if external then store if it is an api call.
      if method.is_external():
        if(method.is_android_api()):
          m = str(method.get_method())
          d_api[m] = len(method.xreffrom)

      # extract opcodes by reading through smali code 
      else: 
        for ins in method.get_method().get_instructions():    
          opcodes[ins.get_name()] = opcodes.get(ins.get_name(), 0) + 1

    return {'permissions': permissions, 'intents' : intents, 'opcodes' : opcodes, 'apis': d_api}

      # 
    
  # Get permissions name from one_hot_encoding
  def get_one_hot_encode_to_name(self, one_hot_encoding, is_permission):
    final_list = []
    mapping = []
    if is_permission:
      mapping = self.official_permissions
    else:
      mapping = self.official_intents
    i = 0
    for code in one_hot_encoding:
      if code == 1:
        final_list.append(mapping[i])
      i += 1
    return final_list
  

  # get Dataframe from dictionary:
  def get_dataframe_from_dictionary_data(self, data_dictionary):
    dictionary = {}
    for data in data_dictionary:
      for key in data.keys():
        dictionary[key] = []
    
    for data in data_dictionary:
      for key in dictionary.keys():
        if key in data.keys():
          dictionary[key].append(data[key])
        else:
          dictionary[key].append(0)
    return pd.DataFrame.from_dict(dictionary)
  # Write feature vector to csv:
  def get_feature_vector_to_dataframe(self, app_feature_vectors, feature_list, label=1):
    names_data = []
    permissions_data = []
    intents_data = []
    opcodes_data = []
    apis_data = []
    
    for app_data in app_feature_vectors:
        names_data.append(app_data[0])
        feature_vector =  app_data[1]
        permissions_data.append(feature_vector['permissions'])
        intents_data.append(feature_vector['intents'])
        opcodes_data.append(feature_vector['opcodes'])
        apis_data.append(feature_vector['apis'])
    
    final_df = []
    # Collect final dataframes that need to be stored
    if 'permissions' in feature_list:
      dataframe_permissions = pd.DataFrame(permissions_data, columns=self.official_permissions)
      dataframe_permissions.insert(0, 'Name', names_data, False)
      final_df.append(dataframe_permissions.sort_values(by=['Name']))
    
    if 'intents' in feature_list:
      dataframe_intents = pd.DataFrame(intents_data, columns=self.official_intents)
      dataframe_intents.insert(0, 'Name', names_data, False)
      final_df.append(dataframe_intents.sort_values(by=['Name']))
    
    if 'opcodes' in feature_list:
      df_o = self.get_dataframe_from_dictionary_data(opcodes_data)
      df_o.insert(0, 'Name', names_data, False)
      final_df.append(df_o.sort_values(by=['Name']))
    
    if 'apis' in feature_list:
      df_i = self.get_dataframe_from_dictionary_data(apis_data)
      df_i.insert(0, 'Name', names_data, False)
      final_df.append(df_i.sort_values(by=['Name']))

    # merge data frames
    f_df = final_df[0]
    for df in final_df[1:]:
      f_df = f_df.merge(df, on='Name')
    
    return f_df
  
  # Get the feature vector for application specified by location
  # redcution_technique = lsi or lda based feature vector.
  # --------------- Add the feature from lsi and hdp -------------------------------------
  def get_application_feature_vector(self, location, reduction_technique):
    extracted_features = self.extract_feature_from_application(location)
    feature_vector = []

    if reduction_technique == 'lsi':
      feature_vector = self.reduction_technique.get_opcodes_topic_distribution(model_name="lsi_opcode_only_40", feature=extracted_features['opcodes'])  
    
    elif reduction_technique == 'lda':  
      feature_vector = self.reduction_technique.get_apis_topic_distribution(model_name="hdp_api_only_150", feature=extracted_features['apis'])    
    
    else:
      feature_vector = []
    return self.add_permission_and_intents_to_feature_vector(extracted_features, feature_vector) 
   
    