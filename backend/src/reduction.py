import pickle

import gensim

from backend.src import constants

class ReductionTechniques:
  
  def __init__(self):
    self.root_path = constants.root_pretrained_reduction_models_path

  # Reformat the feature to the corpus accepted by lda/hdp/lsi
  def feature_to_corpus(self, feature, id2word):
    corpus = []

    # Reverse id2word
    dictionary_to_use = {}
    for k in id2word.keys():
      dictionary_to_use[id2word[k]] = k 
    # format the opcode dictionary in corpus format
    
    for key in feature.keys():
      if key in dictionary_to_use.keys():
        corpus.append((dictionary_to_use[key], feature[key]))

    return corpus

  # Get the topic distribution for new app's api calls from saved model
  def get_apis_topic_distribution(self, model_name, feature, number_of_topics=150):
    
    saved_model = gensim.utils.SaveLoad.load(self.root_path + model_name)
    corpus = self.feature_to_corpus(feature, saved_model.id2word)
    
    # extract the topic distribution
    saved_model = saved_model.suggested_lda_model()
    top_topics = saved_model.get_document_topics(corpus, minimum_probability=0.0)
    topic_vec = [0]*number_of_topics
    for j in top_topics:
        index = j[0]
        topic_vec[index] = j[1]
    return topic_vec 

  # Get topic distribution for new app's opcode sequence from saved model
  def get_opcodes_topic_distribution(self, model_name, feature, number_of_topics=40):
    saved_model = gensim.utils.SaveLoad.load(self.root_path + model_name)
    saved_model.projection = gensim.utils.SaveLoad.load(self.root_path + model_name+".projection")
    corpus = self.feature_to_corpus(feature, saved_model.id2word)
    topics = saved_model[corpus]
    topic_vector = []
    for topic in topics:
      topic_vector.append(topic[1])
    return topic_vector

